{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 1: Data Ingestion & Foundation Setup\n",
        "\n",
        "This notebook handles:\n",
        "- Databricks workspace setup\n",
        "- SEC EDGAR data downloading\n",
        "- Bronze layer ingestion into Delta tables\n",
        "- Metadata logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install sec-edgar-downloader pyspark delta-spark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import modules\n",
        "import sys\n",
        "sys.path.append('/Workspace/Repos/genai-legal-doc-poc/src')\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from src.utils.delta_helpers import (\n",
        "    get_spark_session,\n",
        "    initialize_all_tables\n",
        ")\n",
        "from src.ingest.sec_ingest import SECIngestor\n",
        "from src.utils.logger import logger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Spark and Delta tables\n",
        "spark = get_spark_session()\n",
        "initialize_all_tables(spark, database=\"default\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure ingestion parameters\n",
        "TICKER = \"AAPL\"  # Change to your desired ticker\n",
        "FILING_TYPES = [\"10-K\", \"10-Q\"]  # Types of filings to download\n",
        "DATE_RANGE = (\"2023-01-01\", \"2023-12-31\")  # Date range for filings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ingestor and run full pipeline\n",
        "ingestor = SECIngestor(spark=spark)\n",
        "\n",
        "# Download and ingest SEC filings\n",
        "count = ingestor.run_full_ingestion(\n",
        "    ticker=TICKER,\n",
        "    filing_types=FILING_TYPES,\n",
        "    date_range=DATE_RANGE,\n",
        "    database=\"default\"\n",
        ")\n",
        "\n",
        "print(f\"Successfully ingested {count} files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify ingestion\n",
        "spark.sql(f\"SELECT COUNT(*) as total_docs FROM default.bronze_legal_docs\").show()\n",
        "spark.sql(f\"SELECT * FROM default.bronze_legal_docs LIMIT 5\").show(truncate=False)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
